{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xoKC_w6smPb"
   },
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jLBaXt7smPh"
   },
   "source": [
    "En este notebook estudiaremos cómo crear y visualizar árboles de decisión en scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos\n",
    "\n",
    "En este notebook vamos a usar el conjunto de datos sobre flores Iris que ya conocemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2268,
     "status": "ok",
     "timestamp": 1583143132764,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "IIYggMWbsmPm",
    "outputId": "e5789fe7-9009-4f3d-f932-4026518b1b3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target', 'DESCR', 'target_names', 'feature_names', 'data', 'filename']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "# Cargamos el dataset del iris\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos a utilizar árboles de decisión, __no__ es necesario reescalar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dibujar el árbol de decisión\n",
    "\n",
    "Vamos a construir un árbol de decisión usando los parámetros por defecto y a dibujarlo para analizar cuales son las variables más importantes (las que mejor discriminan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnjSnAi5smP1"
   },
   "outputs": [],
   "source": [
    "# Creamos un árbol de decisión con la configuración por defecto y lo entrenamos\n",
    "clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "clf = clf.fit(iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3752,
     "status": "ok",
     "timestamp": 1583143134262,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "KBfr3JOZsmQK",
    "outputId": "ae8c2601-204c-4ad4-b4c4-1bc89fa71332"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name plot_tree",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3f7a2c06d382>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Pintamos el árbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name plot_tree"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pintamos el árbol\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(clf, filled=True, feature_names=iris['feature_names'], class_names=iris['target_names'], rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algortimo que se usa para construir el árbol hace que los primeros niveles del árbol contengan las variables que mejor discriminan las clases que estamos tratando de modelar. En este caso serían \"petal length (cm)\" y \"petal width (cm)\". De hecho, podemos observar que la variable \"petal length (cm)\" permite separar por si mima la clase de las setosas.\n",
    "\n",
    "También podemos observar que el árbol termina separando todas las clases perfectamente porque ninguna de sus hojas tiene ejemplos de dos clases distintas. ¡Ojo! esto no quiere decir que el árbol sea un clasificador perfecto, sólo significa que clasifica de forma perfecta el conjunto de datos que hemos usado para entrenarlo (puede haber sobreaprendido).\n",
    "\n",
    "En esta imagen puedes ver una de las grandes ventajas de los árboles de decisión: construyen __modelos fácilmente interpretables__.\n",
    "\n",
    "En el algoritmo que hemos visto en clase usamos la _entropía_ como métrica para elegir la siguiente mejor variable. En sklearn, por defecto, usan el [Índice de Gini](https://medium.com/analytics-steps/understanding-the-gini-index-and-information-gain-in-decision-trees-ab4720518ba8) que es una métrica alternativa que persigue el mismo objetivo. En cualquier caso, al construir el árbol de decisión podemos elegir cual de las dos métricas queremos utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvLCwApIsmQS"
   },
   "source": [
    "## Estimando el error\n",
    "\n",
    "Podemos comenzar midiendo el error de nuestro clasificador haciendo una partición del conjunto de datos en dos partes: entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1583143132767,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "4lw3Qo0FsmQV",
    "outputId": "af00902b-09b4-41e3-8bc5-d9d369fccab7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Partimos el conjunto de datos en entrenamiento (70%) y test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# Creamos y entrenamos el árbol de decisión con los parámetros por defecto\n",
    "clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculamos la precisión del modelo de entrenamiento y de test\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como el árbol clasifica perfectamente el conjunto de entrenamiento pero no lo hace tan bien con el conjunto de test. Parece que nuestro modelo ha sobreaprendido.\n",
    "\n",
    "Si queremos tener unos valores más confiables del error podemos utilizar validación cruzada. Aunque la validación cruzada es mucho más costosa computacionalmente, en este caso no notaremos la diferencia porque el conjunto de datos es muy pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Creamos y entrenamos el árbol de decisión con los parámetros por defecto\n",
    "clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# Validación cruzada dividiendo el conjunto de datos en 10 partes (folds)\n",
    "scores = cross_validate(clf, iris['data'], iris['target'], scoring='accuracy', \n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "# scores es un diccionario con datos sobre tiempos y exactitud (accuracy)\n",
    "train_accuracy = np.mean(scores['train_score'])\n",
    "test_accuracy = np.mean(scores['test_score'])\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como, en realidad, el árbol se comporta un poco mejor de lo que parecía con la partición simple. Tenemos un 95.33% de exactitud (accuracy) en el conjunto de test.\n",
    "\n",
    "¿Podemos hacerlo mejor configurando el árbol de decisión? Hay varios parámetros que podemos configurar:\n",
    "\n",
    "- criterio de selección de variables: entropía o gini.\n",
    "- profundidad máxima del árbol\n",
    "- mínimo número de muestras de un nodo para seguir dividiendo \n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3745,
     "status": "ok",
     "timestamp": 1583143134264,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "GFX9I6zMsmQb",
    "outputId": "7a6a7e25-16d7-449b-c780-687a095661ce"
   },
   "outputs": [],
   "source": [
    "# Repetimos el proceso pero modificando los parámetros de aprendizaje del árbol\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",  # por defecto Gini pero podemos cambiar a entropía\n",
    "                             max_depth=4,          # profundidad máxima del árbol\n",
    "                             min_samples_split=5,  # mínimo de muestras en el nodo para seguir dividiéndolo\n",
    "                             random_state=RANDOM_STATE)\n",
    "\n",
    "# Validación cruzada dividiendo el conjunto de datos en 10 partes (folds)\n",
    "scores = cross_validate(clf, iris['data'], iris['target'], scoring='accuracy', \n",
    "                        cv=10, return_train_score=True)\n",
    "\n",
    "train_accuracy = np.mean(scores['train_score'])\n",
    "test_accuracy = np.mean(scores['test_score'])\n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C379Om9VsmQi"
   },
   "source": [
    "Este árbol parece un poco menos sobreajustado que el anterior. Mejora ligeramente la exactitud en el conjunto de test y no tiene un valor tan alto en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAzcJi3RsmQl"
   },
   "source": [
    "## Optimizando los parámetros de un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jks0Giq9smQn"
   },
   "source": [
    "Limitar la profundidad máxima del árbol de decisión puede servir para obtener un clasificador menos \"ajustado\" a los datos de entrenamiento y, por tanto, que generalice mejor en datos nuevos.\n",
    "Podemos calcular la profundidad optima usando validación cruzada y probando distintos valores de ese parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7U-t3HfsmQq"
   },
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# Entrenamos y validamos varios árboles con distintas profundidades máximas\n",
    "max_depths = range(1, 6)\n",
    "for md in max_depths: \n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=md, min_samples_split=2, random_state=RANDOM_STATE)\n",
    "    scores = cross_validate(clf, iris['data'], iris['target'], scoring='accuracy', cv=10, return_train_score=True)\n",
    "    \n",
    "    train_accuracy.append(np.mean(scores['train_score']))\n",
    "    test_accuracy.append(np.mean(scores['test_score']))\n",
    "    \n",
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3719,
     "status": "ok",
     "timestamp": 1583143134271,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "0yZ1x4hqsmQv",
    "outputId": "de79a6c2-c900-4a48-8229-f309b4c939bd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(max_depths, train_accuracy, color=\"r\",  label=\"Training\")\n",
    "plt.plot(max_depths, test_accuracy, color=\"g\", label=\"Test\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Curva de aprendizaje\")\n",
    "plt.xlabel(\"Parametro\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BPzdlYrsmQ2"
   },
   "source": [
    "Para max_depth=3 obtenemos el mejor valor de exactitud para el conjunto de test. A partir de esa profundidad la métrica mejora para el conjunto de entrenamiento y empeora para el conjunto de test indicando que el clasificador está sobre-entrenado y generaliza peor.\n",
    "\n",
    "Podríamos hacer lo mismo con el resto de parámetros del árbol hasta encontrar lo que funcionan mejor para nuestro conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas detalladas por clase\n",
    "\n",
    "Primero vamos a calcular las métricas detalladas agregadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las métricas que vamos a evaluar para cada una de las clases\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Escribimos las métricas que queremos evaluar\n",
    "scoring_metrics = ['precision_weighted', 'recall_weighted','f1_weighted']\n",
    "\n",
    "# Construimos el clasificador\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_split=2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Calculamos las métricas utilizando validación cruzada\n",
    "scores = cross_validate(clf, iris['data'], iris['target'], scoring=scoring_metrics, \n",
    "                        cv=10, return_train_score=False)\n",
    "\n",
    "# Mostrar las métricas agregadas\n",
    "print('Precisión ponderada media: ',np.mean(scores['test_precision_weighted']))\n",
    "print('Exhaustividad ponderada media: ',np.mean(scores['test_recall_weighted']))\n",
    "print('F1 ponderado media: ',np.mean(scores['test_f1_weighted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación calculamos las métricas detalladas por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Esta función entrena 10 clasificadores usando validación cruzada y devuelve una predicción\n",
    "# para cada punto usando el clasificador que no fue entrenado con ese punto\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_split=2, random_state=RANDOM_STATE)\n",
    "predictions = cross_val_predict(clf, iris['data'], iris['target'], cv=10)\n",
    "\n",
    "# Informe por clases\n",
    "cr = classification_report(iris['target'],predictions, target_names=iris['target_names'])\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habíamos visto en el dibujo del árbol, la clase de las setosas se puede clasificar perfectamente. En las clases versicolor y virginica obtenemos una precisión y exahustividad del 94%.\n",
    "\n",
    "Finalmente vamos a pintar la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función extraída de\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El parámetro normalize permite mostrar los porcentajes en lugar del número de instancias\n",
    "plot_confusion_matrix(iris['target'], predictions, iris['target_names'], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWzDHZqIsmQ5"
   },
   "source": [
    "## Entrenando el clasificador final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OdbSv3jsmQ7"
   },
   "source": [
    "Una vez hemos determinado la mejor combinación de parámetros del clasificador (evitando sobreaprender) y hemos calculado cuál es el rendimiento esperable del modelo (usando por ejemplo validación cruzada), podemos entrenar un nuevo modelo con todos los datos y usarlo en \"producción\" cuando nos lleguen nuevos datos.\n",
    "\n",
    "En el caso de los árboles, también puede ser interesante para visualizar el modelo y determinar las variables más importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUNJGcBIsmQ9"
   },
   "outputs": [],
   "source": [
    "# Suponemos la siguiente combinación como la mejor (probablemente no es cierto)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_split=2, random_state=RANDOM_STATE)\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3737,
     "status": "ok",
     "timestamp": 1583143134267,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "xsOStr47smRD",
    "outputId": "d505e023-b77f-42ca-aaca-bea2f9381d01"
   },
   "outputs": [],
   "source": [
    "# Pintamos el árbol\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_tree(clf, filled=True, feature_names=iris['feature_names'], class_names=iris['target_names'], rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar como nuestro árbol \"optimo\" tiene hojas no puras que contiene ejemplos de varias clase. En esos casos el clasificador elegirá la clase mayoritaria para hacer la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda puedes ver como podríamos usar este clasificador para predecir la clase de un nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3728,
     "status": "ok",
     "timestamp": 1583143134268,
     "user": {
      "displayName": "Antonio F. G. Sevilla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJK26ezUmFiR-sSPyTXzdsrzgUQNu4IDTtlDkF=s64",
      "userId": "04480653093805529916"
     },
     "user_tz": -60
    },
    "id": "oucle-CTsmRJ",
    "outputId": "997f706f-4189-41e0-ffd8-03813e3f0fc0"
   },
   "outputs": [],
   "source": [
    "# Predecimos el valor de un ejemplo que nunca hemos visto\n",
    "# podemos pasar un array de nuevos ejemplos y nos devolverá un array de clases\n",
    "clase = clf.predict([[5, 3, 1, 0.1]])\n",
    "# Nos da la clase 0 que es setosa\n",
    "clase[0], iris['target_names'][clase[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41zBTusmsmRQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "07-Árboles de decisión.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
